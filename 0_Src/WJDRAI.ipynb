{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fsmox/GameAI/blob/main/src/WJDRAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27mzp2p6EX9V"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from torchvision.transforms import functional as F\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running locally. Data folder set to: /workspace/examples/0_Src\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# 检查是否在 Google Colab 环境中\n",
        "def is_colab():\n",
        "    try:\n",
        "        import google.colab\n",
        "        return True\n",
        "    except ImportError:\n",
        "        return False\n",
        "\n",
        "# 根据运行环境设置数据文件夹路径\n",
        "if is_colab():\n",
        "    DataFolder = 'drive/MyDrive/AIData'\n",
        "    sys.path.append('/content/drive/MyDrive/Colab Notebooks')\n",
        "    from Model import CaptureDataset, ResizePad,ClickPredictionModel\n",
        "    print(\"Running on Google Colab. Data folder set to:\", DataFolder)\n",
        "else:\n",
        "    sys.path.append(os.getcwd())\n",
        "    from Model import CaptureDataset, ResizePad,ClickPredictionModel\n",
        "    DataFolder = os.path.join(os.getcwd())\n",
        "    modle_path = os.path.join(os.getcwd(), 'Modle','click_prediction_model.pth')\n",
        "    print(\"Running locally. Data folder set to:\", DataFolder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bda1TXpDr3sh"
      },
      "outputs": [],
      "source": [
        "DataFolder = os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install py7zr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import py7zr\n",
        "\n",
        "# 获取当前目录\n",
        "current_directory = os.getcwd()\n",
        "\n",
        "# 查找当前目录下的 Data.7z 文件\n",
        "data_file = os.path.join(current_directory, 'Data.7z')\n",
        "\n",
        "if os.path.exists(data_file):\n",
        "    # 解压到 DataFolder 文件夹\n",
        "    with py7zr.SevenZipFile(data_file, mode='r') as z:\n",
        "        z.extractall(path=DataFolder)\n",
        "        print(f\"文件 {data_file} 解压到 {DataFolder} 文件夹.\")\n",
        "else:\n",
        "    print(f\"文件 {data_file} 不存在.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "-W6VgDPvFL4B",
        "outputId": "01be402d-b689-45b2-ab6d-1990e1e6ff6a"
      },
      "outputs": [],
      "source": [
        "# prompt: 从本地上传数据（data.7z）到工作空间,并解压到data文件夹\n",
        "\n",
        "!pip install py7zr\n",
        "\n",
        "import py7zr\n",
        "\n",
        "# 上传数据\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 解压到data文件夹\n",
        "for fn in uploaded.keys():\n",
        "  if fn.endswith('.7z'):\n",
        "    with py7zr.SevenZipFile(fn, mode='r') as z:\n",
        "      z.extractall(path=DataFolder)\n",
        "      print(f'文件 {fn} 解压到 data 文件夹.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8wRpDi3G9EX",
        "outputId": "ec989649-044e-4603-856e-ef41051d6a31"
      },
      "outputs": [],
      "source": [
        "# prompt: 获取当前文件所在目录\n",
        "\n",
        "import os\n",
        "\n",
        "current_directory = os.getcwd()\n",
        "print(f\"当前文件所在目录: {current_directory}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "iQq8OSejryyQ"
      },
      "outputs": [],
      "source": [
        "class ResizePad:\n",
        "    def __init__(self, target_size, fill=0):\n",
        "        \"\"\"\n",
        "        :param target_size: (width, height) 目标尺寸，例如 (224, 224)\n",
        "        :param fill: 填充颜色（单通道值或 RGB 元组），默认为 0（黑色）\n",
        "        \"\"\"\n",
        "        self.target_w, self.target_h = target_size\n",
        "        self.fill = fill\n",
        "\n",
        "    def __call__(self, image):\n",
        "        # 原始尺寸\n",
        "        orig_w, orig_h = image.size\n",
        "        # 计算缩放因子：保持长宽比例，使得缩放后的图像尺寸不超过目标尺寸\n",
        "        scale = min(self.target_w / orig_w, self.target_h / orig_h)\n",
        "        new_w = int(orig_w * scale)\n",
        "        new_h = int(orig_h * scale)\n",
        "\n",
        "        # 缩放图片\n",
        "        image = F.resize(image, (new_h, new_w))\n",
        "\n",
        "        # 计算左右和上下填充量\n",
        "        pad_w = self.target_w - new_w\n",
        "        pad_h = self.target_h - new_h\n",
        "\n",
        "        # 左右、上下均分填充（如果不均分，可根据需求调整）\n",
        "        left = pad_w // 2\n",
        "        top = pad_h // 2\n",
        "        right = pad_w - left\n",
        "        bottom = pad_h - top\n",
        "\n",
        "        # 填充图片\n",
        "        image = F.pad(image, (left, top, right, bottom), fill=self.fill)\n",
        "        return image\n",
        "\n",
        "# 自定义 Dataset，适用于文件名格式为：\n",
        "# {now}_{screenshot_counter}_{x1}_{y1}_{x2}_{y2}_{Pressed_x}_{Pressed_y}_{x}_{y}_{extra}.png\n",
        "class CaptureDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        # 筛选出所有png文件\n",
        "        self.image_files = [f for f in os.listdir(root_dir) if f.endswith('.png')]\n",
        "        # 正则表达式匹配11个字段，日期和时间字段允许包含'-'，其他字段均为数字\n",
        "        self.filename_pattern = re.compile(\n",
        "            r\"(\\d+-\\d+-\\d+_\\d+-\\d+-\\d+)_(\\d+)_x1_(\\d+)_y1_(\\d+)_x2_(\\d+)_y2_(\\d+)_Px_(\\d+)_Py_(\\d+)_Rx_(\\d+)_Ry_(\\d+)\\.png\"\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_files[idx]\n",
        "        img_path = os.path.join(self.root_dir, img_name)\n",
        "\n",
        "        match = self.filename_pattern.match(img_name)\n",
        "        if not match:\n",
        "            raise ValueError(f\"文件名格式错误: {img_name}\")\n",
        "        groups = match.groups()\n",
        "        # 根据文件名说明：\n",
        "        # groups[0]: now (日期，如 \"2025-03-15\")\n",
        "        # groups[1]: screenshot_counter (时间，如 \"18-13-54\")\n",
        "        # groups[2]: x1, groups[3]: y1, groups[4]: x2, groups[5]: y2\n",
        "        # groups[6]: Pressed_x, groups[7]: Pressed_y, groups[8]: x, groups[9]: y\n",
        "        # groups[10]: 额外字段（忽略）\n",
        "        try:\n",
        "            x1 = int(groups[2])\n",
        "            y1 = int(groups[3])\n",
        "            x2 = int(groups[4])\n",
        "            y2 = int(groups[5])\n",
        "            Pressed_x = int(groups[6]) - x1\n",
        "            Pressed_y = int(groups[7]) - y1\n",
        "            Px = Pressed_x / (x2 - x1)\n",
        "            Py = Pressed_y / (y2 - y1)\n",
        "            # groups[8] 和 groups[9] 可能是其他坐标，暂时忽略\n",
        "            x = int(groups[8])\n",
        "            y = int(groups[9])\n",
        "            # print(f\"文件名: {img_name}\")\n",
        "            # print(f\"x1: {x1}, y1: {y1}, x2: {x2}, y2: {y2}, Pressed_x: {Pressed_x}, Pressed_y: {Pressed_y}\")\n",
        "            # print(f\"{img_name}, Px: {Px}, Py: {Py}\")\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"解析数字失败，文件名: {img_name}\") from e\n",
        "\n",
        "        # 加载图像并转换\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # 输入参数为 (x1, y1, x2, y2)，目标参数为 (Pressed_x, Pressed_y, x, y)\n",
        "        input_tensor = torch.tensor([x1, y1, x2, y2], dtype=torch.float32)\n",
        "        # target_tensor = torch.tensor([Pressed_x, Pressed_y, x, y], dtype=torch.float32)\n",
        "        target_tensor = torch.tensor([Px, Py], dtype=torch.float32)\n",
        "\n",
        "        return image, input_tensor, target_tensor\n",
        "\n",
        "def DataLoderTest():\n",
        "    # 获取当前脚本所在目录，并拼接 Capture 文件夹路径\n",
        "    # current_dir = os.path.dirname(os.path.abspath(__file__))\n",
        "    # current_dir = os.getcwd()\n",
        "    # capture_folder = os.path.join(current_dir, DataFolder)\n",
        "    capture_folder = os.path.join(DataFolder, \"Data\")\n",
        "    print(\"Capture folder:\", capture_folder)\n",
        "\n",
        "    # 定义图像预处理（调整尺寸和归一化，符合 ResNet50 要求）\n",
        "    transform = transforms.Compose([\n",
        "        ResizePad((224, 224), fill=(0, 0, 0)),  # 使用黑色填充\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                            std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # 初始化 Dataset 和 DataLoader\n",
        "    dataset = CaptureDataset(root_dir=capture_folder, transform=transform)\n",
        "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0)\n",
        "\n",
        "    count = 0\n",
        "    # 测试 DataLoader 是否正确加载数据\n",
        "    for images, inputs, targets in dataloader:\n",
        "        # print(\"Image batch shape:\", images.shape)   # 应为 (batch_size, 3, 224, 224)\n",
        "        # print(\"Input params shape:\", inputs.shape)    # 应为 (batch_size, 4)\n",
        "        # print(\"Target shape:\", targets.shape)         # 应为 (batch_size, 4)\n",
        "        for i in range(5):\n",
        "            x1, y1, x2, y2 = inputs[i][0], inputs[i][1], inputs[i][2], inputs[i][3]\n",
        "            P_x, P_y = targets[i][0], targets[i][1]\n",
        "            print(P_x, P_y)\n",
        "            now_width = 224/(y2 - y1) * (x2 - x1)\n",
        "            target_x = now_width * P_x + (224 - now_width)/2\n",
        "            target_y = 224 * P_y\n",
        "            print(f\"Image: {images[i].shape}, Input: {inputs[i]}, Target: {targets[i]}\")\n",
        "            print(f\"Target coordinates: ({target_x.item()}, {target_y.item()})\")\n",
        "            # 反归一化图像数据\n",
        "            mean = torch.tensor([0.485, 0.456, 0.406])\n",
        "            std = torch.tensor([0.229, 0.224, 0.225])\n",
        "            img = images[i] * std[:, None, None] + mean[:, None, None]\n",
        "            img = img.permute(1, 2, 0).numpy()  # 调整维度顺序以适应 matplotlib\n",
        "            img = (img * 255).astype('uint8')  # 转换为 uint8 类型\n",
        "            plt.scatter(target_x.item(), target_y.item(), color='red', s=80)\n",
        "            plt.imshow(img)\n",
        "            plt.show()\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OtWP9cID2yG"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    # 检查设备\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    use_mps = torch.backends.mps.is_available()\n",
        "    if use_cuda:\n",
        "        device = torch.device(\"cuda\")\n",
        "        print(\"Using CUDA\")\n",
        "    elif use_mps:\n",
        "        device = torch.device(\"mps\")\n",
        "        print(\"Using MPS\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(\"Using CPU\")\n",
        "\n",
        "    # 获取当前脚本所在目录，并拼接 Capture 文件夹路径\n",
        "    # current_dir = os.path.dirname(os.path.abspath(__file__))\n",
        "    current_dir = os.getcwd()\n",
        "    capture_folder = os.path.join(current_dir, DataFolder, \"Data\")\n",
        "\n",
        "    # 定义图像预处理（调整尺寸和归一化，符合 ResNet50 要求）\n",
        "    transform = transforms.Compose([\n",
        "        ResizePad((224, 224), fill=(0, 0, 0)),  # 使用黑色填充\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                            std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # 初始化 Dataset 和 DataLoader\n",
        "    dataset = CaptureDataset(root_dir=capture_folder, transform=transform)\n",
        "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "    # 创建模型\n",
        "    model = ClickPredictionModel().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "    # 读取模型\n",
        "    if os.path.exists(\"click_prediction_model.pth\"):\n",
        "        model.load_state_dict(torch.load(\"click_prediction_model.pth\", map_location=device))\n",
        "\n",
        "    # 训练模型\n",
        "    epochs = 5\n",
        "    loss_fn = nn.SmoothL1Loss()\n",
        "    for epoch in range(epochs):\n",
        "        for img, input_xy, target_xy in dataloader:\n",
        "            img, input_xy, target_xy = img.to(device), input_xy.to(device), target_xy.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output_xy = model(img, input_xy)\n",
        "            loss = loss_fn(output_xy, target_xy)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
        "        # 保存模型\n",
        "        torch.save(model.state_dict(), \"click_prediction_model.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "UuG2du_FMBc6",
        "outputId": "57bb76c7-dc4d-49e0-e50d-645611b5746b"
      },
      "outputs": [],
      "source": [
        "DataLoderTest()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYvVCwjNE5lV",
        "outputId": "b508591f-a9f5-4c8f-bbb1-52ffd133245d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using CUDA\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/root/miniforge3/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/root/miniforge3/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 0.42395153641700745\n",
            "Epoch 1, Loss: 0.11521279811859131\n",
            "Epoch 2, Loss: 0.03988625109195709\n",
            "Epoch 3, Loss: 0.01028021052479744\n",
            "Epoch 4, Loss: 0.02628944255411625\n",
            "Epoch 5, Loss: 0.02246830239892006\n",
            "Epoch 6, Loss: 0.011392440646886826\n",
            "Epoch 7, Loss: 0.014033088460564613\n",
            "Epoch 8, Loss: 0.00950282160192728\n",
            "Epoch 9, Loss: 0.0032489404547959566\n",
            "Epoch 10, Loss: 0.0011984215816482902\n",
            "Epoch 11, Loss: 0.00726602878421545\n",
            "Epoch 12, Loss: 0.00868704728782177\n",
            "Epoch 13, Loss: 0.01581568829715252\n",
            "Epoch 14, Loss: 0.014058161526918411\n",
            "Epoch 15, Loss: 0.008701351471245289\n",
            "Epoch 16, Loss: 0.005640676710754633\n",
            "Epoch 17, Loss: 0.011628246866166592\n",
            "Epoch 18, Loss: 0.006973958574235439\n",
            "Epoch 19, Loss: 0.009608757682144642\n",
            "Epoch 20, Loss: 0.01585082709789276\n",
            "Epoch 21, Loss: 0.013188421726226807\n",
            "Epoch 22, Loss: 0.009809138253331184\n",
            "Epoch 23, Loss: 0.009380974806845188\n",
            "Epoch 24, Loss: 0.007588293869048357\n",
            "Epoch 25, Loss: 0.002967640059068799\n",
            "Epoch 26, Loss: 0.011098530143499374\n",
            "Epoch 27, Loss: 0.013190196827054024\n",
            "Epoch 28, Loss: 0.010638413950800896\n",
            "Epoch 29, Loss: 0.005507508292794228\n",
            "Epoch 30, Loss: 0.019234489649534225\n",
            "Epoch 31, Loss: 0.0035755932331085205\n",
            "Epoch 32, Loss: 0.002172447508201003\n",
            "Epoch 33, Loss: 0.015535603277385235\n",
            "Epoch 34, Loss: 0.000891326111741364\n",
            "Epoch 35, Loss: 0.0008982672588899732\n",
            "Epoch 36, Loss: 0.011753526516258717\n",
            "Epoch 37, Loss: 0.006911266129463911\n",
            "Epoch 38, Loss: 0.010089932940900326\n",
            "Epoch 39, Loss: 0.00944913737475872\n",
            "Epoch 40, Loss: 0.008715915493667126\n",
            "Epoch 41, Loss: 0.00363237620331347\n",
            "Epoch 42, Loss: 0.015719661489129066\n",
            "Epoch 43, Loss: 0.00982031598687172\n",
            "Epoch 44, Loss: 0.008975218050181866\n",
            "Epoch 45, Loss: 0.02426890842616558\n",
            "Epoch 46, Loss: 0.007488714065402746\n",
            "Epoch 47, Loss: 0.012308912351727486\n",
            "Epoch 48, Loss: 0.008737258613109589\n",
            "Epoch 49, Loss: 0.006288592237979174\n"
          ]
        }
      ],
      "source": [
        "# 检查设备\n",
        "use_cuda = torch.cuda.is_available()\n",
        "use_mps = torch.backends.mps.is_available()\n",
        "if use_cuda:\n",
        "  device = torch.device(\"cuda\")\n",
        "  print(\"Using CUDA\")\n",
        "elif use_mps:\n",
        "  device = torch.device(\"mps\")\n",
        "  print(\"Using MPS\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print(\"Using CPU\")\n",
        "\n",
        "# 获取当前脚本所在目录，并拼接 Capture 文件夹路径\n",
        "# current_dir = os.path.dirname(os.path.abspath(__file__))\n",
        "current_dir = os.getcwd()\n",
        "capture_folder = os.path.join(current_dir, DataFolder, \"Data\")\n",
        "\n",
        "# 定义图像预处理（调整尺寸和归一化，符合 ResNet50 要求）\n",
        "transform = transforms.Compose([\n",
        "    ResizePad((224, 224), fill=(0, 0, 0)),  # 使用黑色填充\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 初始化 Dataset 和 DataLoader\n",
        "dataset = CaptureDataset(root_dir=capture_folder, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "# 创建模型\n",
        "model = ClickPredictionModel().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "\n",
        "\n",
        "# 读取模型\n",
        "if os.path.exists(modle_path):\n",
        "  model.load_state_dict(torch.load(modle_path, map_location=device))\n",
        "\n",
        "# 训练模型\n",
        "epochs = 50\n",
        "loss_fn = nn.SmoothL1Loss()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for img, input_xy, target_xy in dataloader:\n",
        "    img, input_xy, target_xy = img.to(device), input_xy.to(device), target_xy.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output_xy = model(img, input_xy)\n",
        "    loss = loss_fn(output_xy, target_xy)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
        "  # 保存模型\n",
        "  torch.save(model.state_dict(), modle_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzkSBoENJxXH",
        "outputId": "f70758fe-5473-4d99-b7a5-050def28e730"
      },
      "outputs": [],
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "use_cuda"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3OiqiJZOE8q6"
      },
      "source": [
        "# 新段落"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXUlzuzcERCf",
        "outputId": "2a2cdbda-715d-4dd9-88de-d29821bf8beb"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPUh6BnVTbRY6nMCscjZWQW",
      "cell_execution_strategy": "setup",
      "gpuType": "T4",
      "include_colab_link": true,
      "mount_file_id": "1UX1FqeezzAeymuiVd_fcunrkPPJ7wlzV",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (base)",
      "language": "python",
      "name": "base"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
